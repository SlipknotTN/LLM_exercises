{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "The dataset is the parsed version of the Wikipedia page https://it.wikipedia.org/wiki/Castelnuovo_di_Garfagnana in Italian language.\n",
    "\n",
    "It is an interesting use case because the OpenAI model without additional context is able to answer correctly to some English questions, but it completely fails in Italian providing random answers. The data is probably present in the training dataset only in English, partially and it is under-represented.\n",
    "\n",
    "Using RAG it is possible to see how the answers correctness improve, although they tend to be more coincise. The length of the answer may be extended by providing a different prompt template.\n",
    "\n",
    "The RAG pipeline works also with English questions (the prompt template is in English and the answer language will be the same of the question), but it better performs with Italian questions. With English questions there is more probability to get the \"I don't know\" answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "Parse the Wikipedia page and create a pandas DataFrame with a \"text\" column with a sentence in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee8ed44-1596-4ae1-ae3f-b069e46534e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_TITLE = \"Castelnuovo di Garfagnana\"\n",
    "OUTPUT_DATA_FILEPATH = \"./data/wiki_it_castelnuovo_garfagnana_nb.csv\"\n",
    "WIKIPEDIA_LANG = \"it\"\n",
    "SKIP_SECTIONS = [\"Collegamenti_esterni\", \"Altri_progetti\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: probably there is a nested list; it will be squashed into a single level, list element content: 'Liceo Scientifico Galileo Galilei; I.P.S.I.A. Simone Simoni (indirizzi: elettrici-meccanici); I.T.I. (indirizzi: elettrotecnica-meccanica e meccatronica)'\n",
      "WARNING: probably there is a nested list; it will be squashed into a single level, list element content: 'I.T.C.G. Luigi Campedelli (indirizzi: geometri-ragioneria)'\n",
      "80 sentences obtained from the page 'Castelnuovo di Garfagnana'\n",
      "CSV file saved to './data/wiki_it_castelnuovo_garfagnana_nb.csv'\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import bs4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_dict_key_from_headings(\n",
    "    last_h2_level_paragraph: str,\n",
    "    last_h3_level_paragraph: Optional[str] = None,\n",
    "    last_h4_level_paragraph: Optional[str] = None,\n",
    ") -> str:\n",
    "    key = f\"{last_h2_level_paragraph}\"\n",
    "    if last_h3_level_paragraph is not None:\n",
    "        key += f\" - {last_h3_level_paragraph}\"\n",
    "    if last_h4_level_paragraph is not None:\n",
    "        key += f\" - {last_h4_level_paragraph}\"\n",
    "    return key\n",
    "\n",
    "\n",
    "def get_cleaned_text(element) -> str:\n",
    "    \"\"\"\n",
    "    Strip text and remove '\\n' inside the paragraph\n",
    "    \"\"\"\n",
    "    return element.get_text().strip().replace(u\"\\xa0\",\" \").replace(\"\\n\", \" \")\n",
    "\n",
    "# \"query\" action documentation: https://en.wikipedia.org/w/api.php?action=help&modules=query\n",
    "# Don't pass \"explaintext\": 1 to get the text in HTML format. It is a bit more complex to parse, but we have\n",
    "# all the information to understand when a list is present\n",
    "params = {\n",
    "    \"action\": \"query\",\n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": 1,\n",
    "    \"titles\": PAGE_TITLE,\n",
    "    \"exsectionformat\": \"wiki\",\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "resp = requests.get(\n",
    "    f\"https://{WIKIPEDIA_LANG}.wikipedia.org/w/api.php\", params=params\n",
    ")\n",
    "response_dict = resp.json()\n",
    "\n",
    "page_dict = next(iter(response_dict[\"query\"][\"pages\"].values()))\n",
    "title = page_dict[\"title\"]\n",
    "html_text = page_dict[\"extract\"]\n",
    "soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "# Enable for DEBUG\n",
    "#print(soup.prettify())\n",
    "\n",
    "# Use BeatifulSoap the go element by element\n",
    "# headings -> new sectopm level\n",
    "# <p>...</p> sentences\n",
    "# <ul><li>..</li><li>...</li>...</ul> <li> elements to merge\n",
    "sentences_dict = defaultdict(list)\n",
    "last_h2_level_paragraph = None\n",
    "last_h3_level_paragraph = None\n",
    "last_h4_level_paragraph = None\n",
    "for element in soup:\n",
    "    if type(element) == bs4.Tag:\n",
    "        if element.name == \"p\" and last_h2_level_paragraph is None:\n",
    "            # Intro before the first headings\n",
    "            sentences_dict[title].append(get_cleaned_text(element))\n",
    "        elif element.name == \"h2\":\n",
    "            # First level paragraph\n",
    "            last_h2_level_paragraph = element.attrs[\"data-mw-anchor\"]\n",
    "            last_h3_level_paragraph = None\n",
    "            last_h4_level_paragraph = None\n",
    "            building_list = False\n",
    "        elif element.name == \"h3\":\n",
    "            # Second level paragraph\n",
    "            last_h3_level_paragraph = element.attrs[\"data-mw-anchor\"]\n",
    "            last_h4_level_paragraph = None\n",
    "            building_list = False\n",
    "        elif element.name == \"h4\":\n",
    "            # Third level paragraph\n",
    "            last_h4_level_paragraph = element.attrs[\"data-mw-anchor\"]\n",
    "            building_list = False\n",
    "        elif element.name == \"p\":\n",
    "            # Sentence of a paragraph\n",
    "            # Concatenate the headings to provide context\n",
    "            key = get_dict_key_from_headings(\n",
    "                last_h2_level_paragraph,\n",
    "                last_h3_level_paragraph,\n",
    "                last_h4_level_paragraph,\n",
    "            )\n",
    "            # Search for <ul> inside <p>\n",
    "            for p_children in element.children:\n",
    "                if type(p_children) == bs4.Tag and p_children.name == \"ul\":\n",
    "                    raise ValueError(\"List <ul> inside a <p> not supported\")\n",
    "            sentences_dict[key].append(get_cleaned_text(element))\n",
    "\n",
    "        elif element.name == \"ul\" or element.name == \"dl\":\n",
    "            # Get the list elements and merge them when necessary\n",
    "            # DO NOT MERGE when there is no sentence before ending with \":\"\n",
    "            # MERGE when the previous sentence ends with \":\" or when another list element is preceding\n",
    "\n",
    "            # Logic to merge the list elements\n",
    "            list_content_str = \"\"\n",
    "            for list_element in element.children:\n",
    "                if (\n",
    "                    list_element.name == \"li\"\n",
    "                    or list_element.name == \"dd\"\n",
    "                    or list_element.name == \"dt\"\n",
    "                ):\n",
    "                    list_text = get_cleaned_text(list_element)\n",
    "                    list_content_str += list_text + \"\\n\"\n",
    "            list_content_str = (\n",
    "                list_content_str.replace(\"\\n\", \"; \")\n",
    "                .replace(\",;\", \";\")\n",
    "                .replace(\";;\", \";\")\n",
    "                .replace(\".;\", \";\")[: -len(\", \")]\n",
    "            )\n",
    "            key = get_dict_key_from_headings(\n",
    "                last_h2_level_paragraph,\n",
    "                last_h3_level_paragraph,\n",
    "                last_h4_level_paragraph,\n",
    "            )\n",
    "            last_sentence_for_key = (\n",
    "                sentences_dict[key][-1] if len(sentences_dict[key]) > 0 else \"\"\n",
    "            )\n",
    "            if last_sentence_for_key.endswith(\":\"):\n",
    "                # Concatenate the list elements with the previous sentence which explains the list content,\n",
    "                sentences_dict[key][-1] += \" \" + list_content_str\n",
    "            elif last_element_type == \"ul\" or last_element_type == \"dl\":\n",
    "                # The list could already been started with a different ul or dl element,\n",
    "                # in this case we don't support nesting and we simply concatenate\n",
    "                print(\n",
    "                    f\"WARNING: probably there is a nested list; it will be squashed into a single level, list element content: '{list_content_str}'\"\n",
    "                )\n",
    "                sentences_dict[key][-1] += \"; \" + list_content_str\n",
    "            else:\n",
    "                # The list is probably part of an entire section and not introduce with \":\",\n",
    "                # so it does worth keeping split\n",
    "                sentences_dict[key].extend(list_content_str.split(\"; \"))\n",
    "        else:\n",
    "            raise ValueError(f\"Tag {element.name} not supported\")\n",
    "        last_element_type = element.name\n",
    "\n",
    "df_content = {\"text\": []}\n",
    "skip_keys_start = tuple(\n",
    "    [skip_section + \" - \" for skip_section in SKIP_SECTIONS]\n",
    ")\n",
    "for key, key_sentences in sentences_dict.items():\n",
    "    if key not in SKIP_SECTIONS and key.startswith(skip_keys_start) is False:\n",
    "        for key_sentence in key_sentences:\n",
    "            if key_sentence != \"\":\n",
    "                df_content[\"text\"].append(f\"{key} - {key_sentence}\")\n",
    "\n",
    "df = pd.DataFrame.from_dict(df_content)\n",
    "print(f\"{len(df)} sentences obtained from the page '{PAGE_TITLE}'\")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_DATA_FILEPATH), exist_ok=True)\n",
    "df.to_csv(OUTPUT_DATA_FILEPATH)\n",
    "print(f\"CSV file saved to '{OUTPUT_DATA_FILEPATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castelnuovo di Garfagnana - Castelnuovo di Gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geografia_fisica - Territorio - Sorge alla con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geografia_fisica - Clima - Classificazione sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geografia_fisica - Clima - Classificazione cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geografia_fisica - Clima - Diffusività atmosfe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Castelnuovo di Garfagnana - Castelnuovo di Gar...\n",
       "1  Geografia_fisica - Territorio - Sorge alla con...\n",
       "2  Geografia_fisica - Clima - Classificazione sis...\n",
       "3  Geografia_fisica - Clima - Classificazione cli...\n",
       "4  Geografia_fisica - Clima - Diffusività atmosfe..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3fb7742-b31f-45b5-82e0-ce93b93ce606",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAREUM_OPENAI_API_KEY = \"YOUR API KEY\"\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "REQUEST_SIZE = 100\n",
    "MAX_PROMPT_TOKENS = 1000\n",
    "MAX_ANSWER_TOKENS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "582f0656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings...\n",
      "embeddings column added to the dataframe\n",
      "Embeddings space size using text-embedding-ada-002: 1536\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = VOCAREUM_OPENAI_API_KEY\n",
    "\n",
    "# In order to avoid a `RateLimitError` the data is sent in batches to the `Embedding.create` function\n",
    "print(\"Extracting embeddings...\")\n",
    "embeddings = []\n",
    "for i in range(0, len(df), REQUEST_SIZE):\n",
    "    # Send text data to OpenAI model to get embeddings, the embeddings are at sentence level, not word\n",
    "    response = openai.Embedding.create(\n",
    "        input=df.iloc[i : i + REQUEST_SIZE][\"text\"].tolist(),\n",
    "        engine=EMBEDDING_MODEL_NAME,\n",
    "    )\n",
    "\n",
    "    # Add embeddings to list\n",
    "    embeddings.extend([data[\"embedding\"] for data in response[\"data\"]])\n",
    "\n",
    "# Add embeddings list formatted as numpy array to the dataframe\n",
    "df[\"embeddings\"] = embeddings\n",
    "df[\"embeddings\"] = df[\"embeddings\"].apply(np.array)\n",
    "\n",
    "print(\"embeddings column added to the dataframe\")\n",
    "print(\n",
    "    f\"Embeddings space size using {EMBEDDING_MODEL_NAME}: {len(embeddings[0])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castelnuovo di Garfagnana - Castelnuovo di Gar...</td>\n",
       "      <td>[0.01732315681874752, -0.00550642516463995, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geografia_fisica - Territorio - Sorge alla con...</td>\n",
       "      <td>[0.015181456692516804, -0.007471294142305851, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geografia_fisica - Clima - Classificazione sis...</td>\n",
       "      <td>[0.019138965755701065, -0.0005533070070669055,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geografia_fisica - Clima - Classificazione cli...</td>\n",
       "      <td>[0.022875944152474403, -0.00048568969941698015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geografia_fisica - Clima - Diffusività atmosfe...</td>\n",
       "      <td>[-0.0010899270419031382, 0.003765960456803441,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Castelnuovo di Garfagnana - Castelnuovo di Gar...   \n",
       "1  Geografia_fisica - Territorio - Sorge alla con...   \n",
       "2  Geografia_fisica - Clima - Classificazione sis...   \n",
       "3  Geografia_fisica - Clima - Classificazione cli...   \n",
       "4  Geografia_fisica - Clima - Diffusività atmosfe...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.01732315681874752, -0.00550642516463995, 0....  \n",
       "1  [0.015181456692516804, -0.007471294142305851, ...  \n",
       "2  [0.019138965755701065, -0.0005533070070669055,...  \n",
       "3  [0.022875944152474403, -0.00048568969941698015...  \n",
       "4  [-0.0010899270419031382, 0.003765960456803441,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0eb3f-cfc9-4b65-afbd-2539b4cbe8ad",
   "metadata": {},
   "source": [
    "### Utility functions to exploit the embeddings to answer the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import tiktoken\n",
    "from openai.embeddings_utils import distances_from_embeddings, get_embedding\n",
    "\n",
    "# Prompt template to get an answer to the question\n",
    "PROMPT_TEMPLATE = \\\n",
    "\"\"\"\n",
    "Answer the question based on the context below, and if the question can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "def get_rows_sorted_by_relevance(\n",
    "    question: str, df: pd.DataFrame, embedding_model_name: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that takes in input a question string, a dataframe and an embedding model name.\n",
    "    Each dataframe row includes a text and the associated embeddings vector.\n",
    "\n",
    "    Returns:\n",
    "        Copy of the input dataframe sorted by descending question relevance\n",
    "    \"\"\"\n",
    "    # Get embeddings for the question text\n",
    "    question_embeddings = get_embedding(question, engine=embedding_model_name)\n",
    "\n",
    "    # Make a copy of the dataframe and add a \"distances\" column containing\n",
    "    # the cosine distances between each row's embeddings and the\n",
    "    # embeddings of the question\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"distances\"] = distances_from_embeddings(\n",
    "        question_embeddings, df_copy[\"embeddings\"].values, distance_metric=\"cosine\"\n",
    "    )\n",
    "\n",
    "    # Sort the copied dataframe by the distances and return it\n",
    "    # (shorter distance = more relevant so we sort in ascending order)\n",
    "    df_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def count_tokens(text: str, encoding: str = \"cl100k_base\"):\n",
    "    \"\"\"\n",
    "    Count the number of tokens before calculating the embeddings\n",
    "\n",
    "    Args:\n",
    "        text: text for which you want to count the tokens\n",
    "        encoding: encoding name\n",
    "\n",
    "    Returns:\n",
    "        the number of tokens to represent the text\n",
    "    \"\"\"\n",
    "    tokenizer = tiktoken.get_encoding(encoding)\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def answer_question(df_embed: pd.DataFrame, question: str, debug: bool = False) -> List[str]:\n",
    "    # Create the embeddings for the question using under the hood openai.Embedding.create\n",
    "    df_sorted_distances = get_rows_sorted_by_relevance(\n",
    "        question=question,\n",
    "        df=df_embed,\n",
    "        embedding_model_name=EMBEDDING_MODEL_NAME,\n",
    "    )\n",
    "\n",
    "    # We want to exploit the available number of tokens for the model, but setting a limit, \n",
    "    # because we are charged based on the number of tokens\n",
    "    current_token_count = count_tokens(PROMPT_TEMPLATE) + count_tokens(question)\n",
    "    if debug:\n",
    "        print(f\"Prompt template + question number of tokens: {current_token_count}\")\n",
    "\n",
    "    # Add context until max tokens (which can be exceeded with the last step)\n",
    "    context = []\n",
    "    for text in df_sorted_distances[\"text\"].values:\n",
    "\n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = count_tokens(text)\n",
    "        current_token_count += text_token_count\n",
    "\n",
    "        # Add the row of text to the list if we haven't exceeded the max.\n",
    "        # The last step can exceed max_prompt_tokens\n",
    "        if current_token_count <= MAX_PROMPT_TOKENS:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Create the prompt with the context in a specific format to highlight each line (event)\n",
    "    prompt = PROMPT_TEMPLATE.format(\"\\n\\n###\\n\\n\".join(context), question)\n",
    "    if debug:\n",
    "        print(f\"\\nComplete RAG prompt: {prompt}\")\n",
    "        print(f\"\\nComplete RAG prompt tokens: {count_tokens(prompt)}\")\n",
    "\n",
    "    # From the documentation: the token count of your prompt plus max_tokens \n",
    "    # (maximum number of tokens that can be generated in the completion) \n",
    "    # cannot exceed the model's context length.\n",
    "\n",
    "    # Answer without using the context\n",
    "    initial_answer = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=question,\n",
    "        max_tokens=MAX_ANSWER_TOKENS,\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "    # Answer using the context\n",
    "    rag_answer = openai.Completion.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\", prompt=prompt, max_tokens=MAX_ANSWER_TOKENS\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    return initial_answer, rag_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1_it = \"Qual è il monumento simbolo di Castelnuovo di Garfagnana?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial answer without context: Il monumento simbolo di Castelnuovo di Garfagnana è il Castello di Castelnuovo. Costruito nel IX secolo, il castello ha subito numerosi rimaneggiamenti e ampliamenti nel corso dei secoli, diventando uno dei più importanti esempi di architettura militare dell'Italia centrale. Oggi ospita il Museo Archeologico del Territorio della Garfagnana e rappresenta una delle principali attrazioni turistiche della città.\n",
      "RAG answer: La Rocca Ariostesca.\n"
     ]
    }
   ],
   "source": [
    "initial_answer_1, rag_answer_1 = answer_question(df, question_1_it, debug=False)\n",
    "print(f\"Initial answer without context: {initial_answer_1}\")\n",
    "print(f\"RAG answer: {rag_answer_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2_en = \"How is it called the football team of Castelnuovo di Garfagnana?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial answer without context: The football team of Castelnuovo di Garfagnana is called \"A.S.D. Castelnuovo Garfagnana\".\n",
      "RAG answer: The football team of Castelnuovo di Garfagnana is called U.S. Castelnuovo.\n"
     ]
    }
   ],
   "source": [
    "initial_answer_2, rag_answer_2 = answer_question(df, question_2_en, debug=False)\n",
    "print(f\"Initial answer without context: {initial_answer_2}\")\n",
    "print(f\"RAG answer: {rag_answer_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f141a2-268f-43a3-bca2-ba30b3a525ee",
   "metadata": {},
   "source": [
    "### Question loop with user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6d1ca-81a1-453c-ae73-aeaa8d561fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Chi ha governato a Castelnuovo di Garfagnana?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial answer without context: Non siamo in grado di fornire una risposta accurata poiché non abbiamo abbastanza informazioni sul comune di Castelnuovo di Garfagnana. È probabile che il comune sia stato governato da vari sindaci e amministratori locali nel corso dei suoi anni di esistenza. Si consiglia di consultare l'ufficio comunale o un archivio storico locale per ulteriori informazioni.\n",
      "RAG answer: Gli Estensi di Ferrara.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    question_input = input()\n",
    "    initial_answer, rag_answer = answer_question(df, question_input, debug=False)\n",
    "    print(f\"Initial answer without context: {initial_answer}\")\n",
    "    print(f\"RAG answer: {rag_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
