{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "The dataset is the parsed version of the Wikipedia page https://it.wikipedia.org/wiki/Castelnuovo_di_Garfagnana in Italian language.\n",
    "\n",
    "It is an interesting use case because the trained model is able to answer something, but it mades a lot of errors. The data is probably only partially present in the training dataset or under-represented.\n",
    "\n",
    "Using RAG it is possible to see how the answers correctness improve, although they tend to be more coincise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "Parse the Wikipedia page and create a pandas DataFrame with a \"text\" column with a sentence in each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee8ed44-1596-4ae1-ae3f-b069e46534e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_TITLE = \"Castelnuovo di Garfagnana\"\n",
    "OUTPUT_DATA_FILEPATH = \"./data/wiki_it_castelnuovo_garfagnana_nb.csv\"\n",
    "WIKIPEDIA_LANG = \"it\"\n",
    "SKIP_SECTIONS = [\"Collegamenti_esterni\", \"Altri_progetti\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: probably there is a nested list; it will be squashed into a single level, list element content: 'Liceo Scientifico Galileo Galilei; I.P.S.I.A. Simone Simoni (indirizzi: elettrici-meccanici); I.T.I. (indirizzi: elettrotecnica-meccanica e meccatronica)'\n",
      "WARNING: probably there is a nested list; it will be squashed into a single level, list element content: 'I.T.C.G. Luigi Campedelli (indirizzi: geometri-ragioneria)'\n",
      "80 sentences obtained from the page 'Castelnuovo di Garfagnana'\n",
      "CSV file saved to './data/wiki_it_castelnuovo_garfagnana_nb.csv'\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def get_dict_key_from_headings(\n",
    "    last_h2_level_paragraph: str,\n",
    "    last_h3_level_paragraph: Optional[str] = None,\n",
    "    last_h4_level_paragraph: Optional[str] = None,\n",
    ") -> str:\n",
    "    key = f\"{last_h2_level_paragraph}\"\n",
    "    if last_h3_level_paragraph is not None:\n",
    "        key += f\" - {last_h3_level_paragraph}\"\n",
    "    if last_h4_level_paragraph is not None:\n",
    "        key += f\" - {last_h4_level_paragraph}\"\n",
    "    return key\n",
    "\n",
    "\n",
    "def get_cleaned_text(element) -> str:\n",
    "    \"\"\"\n",
    "    Strip text and remove '\\n' inside the paragraph\n",
    "    \"\"\"\n",
    "    return element.get_text().strip().replace(u\"\\xa0\",\" \").replace(\"\\n\", \" \")\n",
    "\n",
    "# \"query\" action documentation: https://en.wikipedia.org/w/api.php?action=help&modules=query\n",
    "# Don't pass \"explaintext\": 1 to get the text in HTML format. It is a bit more complex to parse, but we have\n",
    "# all the information to understand when a list is present\n",
    "params = {\n",
    "    \"action\": \"query\",\n",
    "    \"prop\": \"extracts\",\n",
    "    \"exlimit\": 1,\n",
    "    \"titles\": PAGE_TITLE,\n",
    "    \"exsectionformat\": \"wiki\",\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "resp = requests.get(\n",
    "    f\"https://{WIKIPEDIA_LANG}.wikipedia.org/w/api.php\", params=params\n",
    ")\n",
    "response_dict = resp.json()\n",
    "\n",
    "page_dict = next(iter(response_dict[\"query\"][\"pages\"].values()))\n",
    "title = page_dict[\"title\"]\n",
    "html_text = page_dict[\"extract\"]\n",
    "soup = BeautifulSoup(html_text, \"html.parser\")\n",
    "# Enable for DEBUG\n",
    "#print(soup.prettify())\n",
    "\n",
    "# Use BeatifulSoap the go element by element\n",
    "# headings -> new sectopm level\n",
    "# <p>...</p> sentences\n",
    "# <ul><li>..</li><li>...</li>...</ul> <li> elements to merge\n",
    "sentences_dict = defaultdict(list)\n",
    "last_h2_level_paragraph = None\n",
    "last_h3_level_paragraph = None\n",
    "last_h4_level_paragraph = None\n",
    "for element in soup:\n",
    "    if type(element) == bs4.Tag:\n",
    "        if element.name == \"p\" and last_h2_level_paragraph is None:\n",
    "            # Intro before the first headings\n",
    "            sentences_dict[title].append(get_cleaned_text(element))\n",
    "        elif element.name == \"h2\":\n",
    "            # First level paragraph\n",
    "            last_h2_level_paragraph = element.attrs[\"data-mw-anchor\"]\n",
    "            last_h3_level_paragraph = None\n",
    "            last_h4_level_paragraph = None\n",
    "            building_list = False\n",
    "        elif element.name == \"h3\":\n",
    "            # Second level paragraph\n",
    "            last_h3_level_paragraph = element.attrs[\"data-mw-anchor\"]\n",
    "            last_h4_level_paragraph = None\n",
    "            building_list = False\n",
    "        elif element.name == \"h4\":\n",
    "            # Third level paragraph\n",
    "            last_h4_level_paragraph = element.attrs[\"data-mw-anchor\"]\n",
    "            building_list = False\n",
    "        elif element.name == \"p\":\n",
    "            # Sentence of a paragraph\n",
    "            # Concatenate the headings to provide context\n",
    "            key = get_dict_key_from_headings(\n",
    "                last_h2_level_paragraph,\n",
    "                last_h3_level_paragraph,\n",
    "                last_h4_level_paragraph,\n",
    "            )\n",
    "            # Search for <ul> inside <p>\n",
    "            for p_children in element.children:\n",
    "                if type(p_children) == bs4.Tag and p_children.name == \"ul\":\n",
    "                    raise ValueError(\"List <ul> inside a <p> not supported\")\n",
    "            sentences_dict[key].append(get_cleaned_text(element))\n",
    "\n",
    "        elif element.name == \"ul\" or element.name == \"dl\":\n",
    "            # Get the list elements and merge them when necessary\n",
    "            # DO NOT MERGE when there is no sentence before ending with \":\"\n",
    "            # MERGE when the previous sentence ends with \":\" or when another list element is preceding\n",
    "\n",
    "            # Logic to merge the list elements\n",
    "            list_content_str = \"\"\n",
    "            for list_element in element.children:\n",
    "                if (\n",
    "                    list_element.name == \"li\"\n",
    "                    or list_element.name == \"dd\"\n",
    "                    or list_element.name == \"dt\"\n",
    "                ):\n",
    "                    list_text = get_cleaned_text(list_element)\n",
    "                    list_content_str += list_text + \"\\n\"\n",
    "            list_content_str = (\n",
    "                list_content_str.replace(\"\\n\", \"; \")\n",
    "                .replace(\",;\", \";\")\n",
    "                .replace(\";;\", \";\")\n",
    "                .replace(\".;\", \";\")[: -len(\", \")]\n",
    "            )\n",
    "            key = get_dict_key_from_headings(\n",
    "                last_h2_level_paragraph,\n",
    "                last_h3_level_paragraph,\n",
    "                last_h4_level_paragraph,\n",
    "            )\n",
    "            last_sentence_for_key = (\n",
    "                sentences_dict[key][-1] if len(sentences_dict[key]) > 0 else \"\"\n",
    "            )\n",
    "            if last_sentence_for_key.endswith(\":\"):\n",
    "                # Concatenate the list elements with the previous sentence which explains the list content,\n",
    "                sentences_dict[key][-1] += \" \" + list_content_str\n",
    "            elif last_element_type == \"ul\" or last_element_type == \"dl\":\n",
    "                # The list could already been started with a different ul or dl element,\n",
    "                # in this case we don't support nesting and we simply concatenate\n",
    "                print(\n",
    "                    f\"WARNING: probably there is a nested list; it will be squashed into a single level, list element content: '{list_content_str}'\"\n",
    "                )\n",
    "                sentences_dict[key][-1] += \"; \" + list_content_str\n",
    "            else:\n",
    "                # The list is probably part of an entire section and not introduce with \":\",\n",
    "                # so it does worth keeping split\n",
    "                sentences_dict[key].extend(list_content_str.split(\"; \"))\n",
    "        else:\n",
    "            raise ValueError(f\"Tag {element.name} not supported\")\n",
    "        last_element_type = element.name\n",
    "\n",
    "df_content = {\"text\": []}\n",
    "skip_keys_start = tuple(\n",
    "    [skip_section + \" - \" for skip_section in SKIP_SECTIONS]\n",
    ")\n",
    "for key, key_sentences in sentences_dict.items():\n",
    "    if key not in SKIP_SECTIONS and key.startswith(skip_keys_start) is False:\n",
    "        for key_sentence in key_sentences:\n",
    "            if key_sentence != \"\":\n",
    "                df_content[\"text\"].append(f\"{key} - {key_sentence}\")\n",
    "\n",
    "df = pd.DataFrame.from_dict(df_content)\n",
    "print(f\"{len(df)} sentences obtained from the page '{PAGE_TITLE}'\")\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_DATA_FILEPATH), exist_ok=True)\n",
    "df.to_csv(OUTPUT_DATA_FILEPATH)\n",
    "print(f\"CSV file saved to '{OUTPUT_DATA_FILEPATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a595980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castelnuovo di Garfagnana - Castelnuovo di Gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Geografia_fisica - Territorio - Sorge alla con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geografia_fisica - Clima - Classificazione sis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Geografia_fisica - Clima - Classificazione cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geografia_fisica - Clima - Diffusività atmosfe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Castelnuovo di Garfagnana - Castelnuovo di Gar...\n",
       "1  Geografia_fisica - Territorio - Sorge alla con...\n",
       "2  Geografia_fisica - Clima - Classificazione sis...\n",
       "3  Geografia_fisica - Clima - Classificazione cli...\n",
       "4  Geografia_fisica - Clima - Diffusività atmosfe..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
